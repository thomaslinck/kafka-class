{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to Kafka Lab!","text":"<p>The goal of this material is to get you started with Apache Kafka. You will be watching a series of short videos from Confluent, a company founded by the same people who created Kafka. Along with the videos, you will get the chance of experimenting with the concepts using PWS (our very own distributed server for Kafka). Running the commands should be very quick. Invest some time in understanding what is going on and why outputs are in a certain way. We will dive deeper into each of these topics in class. </p>"},{"location":"#login-to-pws","title":"Login to PWS","text":"<p>All the steps below need to be executed from within PWS. So to get started, open your terminal and ssh into the machine. </p> <p>Information for accessing PWS can be found in the syllabus</p>"},{"location":"#set-up","title":"Set up","text":"<p>Let's start by exporting some env vars. You need to do this every time you ssh into the machine (or add them to your <code>.bashrc</code> in c0, up to you). </p> <pre><code>export KAFKA_PATH='/opt/kafka/bin' \nexport BOOTSTRAP_SERVER='cs0.minerva.local:9092' \n</code></pre>"},{"location":"#inspecting-the-cluster","title":"Inspecting the cluster","text":"<p>To start, run:  <pre><code>${KAFKA_PATH}/kafka-metadata-quorum.sh --bootstrap-server $BOOTSTRAP_SERVER describe --status \n</code></pre></p> <p>This is the first step to make sure that the system is working correctly. Your output should look something like:  <pre><code>ClusterId:              dZmpfrGnSaq_XBDWsSsKPg\nLeaderId:               0\nLeaderEpoch:            25951\nHighWatermark:          140536\nMaxFollowerLag:         0\nMaxFollowerLagTimeMs:   0\nCurrentVoters:          [0,1,2]\nCurrentObservers:       [3,4,5]\n</code></pre></p> <p>CurrentObservers are the actual Kafka brokers that we are interested in. These form our Kafka Cluster. Notice that we have 3 brokers with IDs 3,4,5 (check your own output from terminal). CurrentVoters are the Kafka controllers, responsible for managing consensus. We will not focus on these. </p>"},{"location":"#listing-the-topics","title":"Listing the topics","text":"<p>The command below allows you to see all the topics in our cluster. Remember that a Kafka topic is an abstraction that groups related events together. Consumers can subscribe to topics they are interested to. </p> <p>Tip</p> <p>This command will list a few different topics. There should not be any topic with your name yet. We will create it soon. </p> <pre><code>${KAFKA_PATH}/kafka-topics.sh --list --bootstrap-server $BOOTSTRAP_SERVER\n</code></pre>"},{"location":"#creating-your-own-topic","title":"Creating your own topic","text":"<p>First read the command below. Running this command will create a new topic called <code>&lt;your_username&gt;_topic</code>. Notice that the topic will have both the number of partitions and the replication factor set as 1. </p> <pre><code>${KAFKA_PATH}/kafka-topics.sh --create --bootstrap-server $BOOTSTRAP_SERVER --replication-factor 1 --partitions 1 --topic ${USER}_topic\n</code></pre> <p>Feel free to ignore the warning message. You can ensure that creation was succesful by running all the topics again and finding your own: <pre><code>${KAFKA_PATH}/kafka-topics.sh --list --bootstrap-server $BOOTSTRAP_SERVER\n</code></pre></p>"},{"location":"#inspecting-your-topic","title":"Inspecting your topic","text":"<p>The following command will let you inspect your topic: </p> <pre><code>${KAFKA_PATH}/kafka-topics.sh --describe --bootstrap-server $BOOTSTRAP_SERVER --topic ${USER}_topic\n</code></pre> <p>Answer the following questions:  1. Where is each partition stored?  1. Is this model fault tolerant?  1. Is this model scalable? </p>"},{"location":"#altering-the-number-of-partitions","title":"Altering the number of partitions","text":"<p>Now we will change the number of partitions in the topic. Run: </p> <p><pre><code>${KAFKA_PATH}/kafka-topics.sh --alter --bootstrap-server $BOOTSTRAP_SERVER --topic ${USER}_topic --partitions 3\n</code></pre> If everything is succesful nothing will be printed. Inspect your topic again: </p> <pre><code>${KAFKA_PATH}/kafka-topics.sh --describe --bootstrap-server $BOOTSTRAP_SERVER --topic ${USER}_topic\n</code></pre> <p>Things changed! You should now see 3 partitions. Given that we have exactly 3 brokers, Kafka will assign each partition to a different broker to balance load. </p> <p>Think again about the questions from before, particularly:  1. Is this model fault tolerant?  1. Is this model scalable? </p>"},{"location":"#altering-the-replication-factor","title":"Altering the replication factor","text":"<p>There isn't a way to simply alter the replication factor as we did with the partitions. What we will do instead is to delete your topic, recreate it with the new configuration and finally inspect it: </p> <pre><code>${KAFKA_PATH}/kafka-topics.sh --bootstrap-server $BOOTSTRAP_SERVER --delete --topic ${USER}_topic\n${KAFKA_PATH}/kafka-topics.sh --create --bootstrap-server $BOOTSTRAP_SERVER --replication-factor 2 --partitions 3 --topic ${USER}_topic\n${KAFKA_PATH}/kafka-topics.sh --describe --bootstrap-server $BOOTSTRAP_SERVER --topic ${USER}_topic\n</code></pre> <p>Now you should see each partition being replicated in two brokers: the leader and an additional replica. Once again, Kafka will take care of distributing the partitions evenly across brokers. </p> <p>Think about the questions from before, particularly:  1. Is this model fault tolerant?  1. Is this model scalable? </p>"},{"location":"#writing-and-reading-topics","title":"Writing and reading topics","text":"<p>First of all, duplicate your terminal window. SSH into PWS in the additional window. One tab will be the producer and the other will be the consumer. </p> <p>Create the consumer in one tab by running:  <pre><code>${KAFKA_PATH}/kafka-console-consumer.sh --bootstrap-server $BOOTSTRAP_SERVER --topic ${USER}_topic --from-beginning  --property print.partition=true\n</code></pre></p> <p>You should keep this tab open and running. </p> <p>Then, turn your other tab into a producer by running the command below. You can type messages and press enter to publish them. </p> <pre><code>${KAFKA_PATH}/kafka-console-producer.sh --broker-list $BOOTSTRAP_SERVER --topic ${USER}_topic --producer-property partitioner.class=org.apache.kafka.clients.producer.RoundRobinPartitioner \n</code></pre> <p>As you publish new messages, you will see them showing up in the consumer! This indicates that your topics is working well within the Kafka cluster. </p>"},{"location":"#writing-and-reading-with-keys","title":"Writing and reading with keys","text":"<p>You can now press <code>ctrl+d</code> on your producer. This will close it. Reboot your producer using the following command to enable key:value messages: </p> <pre><code>${KAFKA_PATH}/kafka-console-producer.sh --broker-list $BOOTSTRAP_SERVER --topic ${USER}_topic --property \"parse.key=true\" --property \"key.separator=:\" \n</code></pre> <p>Now you can send messages in the format <code>key:value</code>. For example, you can send <code>name:thomas</code>, where name is the key and thomas is the value. Observe how messages with the same key are sent to the same partition. Play around with a few messages. </p>"},{"location":"#the-end","title":"THE END!","text":"<p>And that's it for today's PCW! You can press <code>ctrl+d</code> on the producer and <code>ctrl+c</code> on the consumer to close both. Then exit PWS and you will be done! </p>"}]}